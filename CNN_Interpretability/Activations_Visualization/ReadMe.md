#Visualizing CNNs' activations are one of the most important and intuitive techniques to understand what are the outputs from your layers.
***First of all, thanks to Francois Chollet for his great book and explanations, part of the code at this repo was developed by him at his book***
<code><img src="https://i.pinimg.com/originals/7b/db/5e/7bdb5e02f5b896af975897a4b5adc4f2.png"></code>

## 1- What are the activations ?
Activations are the output from the CNN layers, also they are called the output feature maps, which mainly generated after using the convolutional operation.


